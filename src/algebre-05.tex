\ifsolo
    ~

    \vspace{1cm}

    \begin{center}
        \textbf{\LARGE Formes quadratiques} \\[1em]
    \end{center}
    \tableofcontents
\else
    \chapter{Formes quadratiques}

    \minitoc
\fi
\thispagestyle{empty}

Dans tout le chapitre, $k$ est un corps, et on supposera que les espaces vectoriels sont de dimension finie.

\section{Forme polaire}


\begin{dfn}
    Soit $E$ un  $k$-ev. Une forme quadratique\index{forme quadratique} sur  $E$ est une application  $q:E \longrightarrow k$ telle qu'il existe $\phi \in  \Bil(E)$ telle que $q(x)=\phi(x, x)$ pour tout  $x \in  E$. On note $Q(E)$ le  $k$-ev des formes quadratiques sur  $E$.
\end{dfn}

\begin{rem}
    Si $q \in  Q(E)$ est associée à $\phi\in \Bil(E)$ et si $(e_1, \cdots , e_n)$ est une base de $E$ alors \[q(x)=\phi(x, x)=\sum_{1\leq i,j\leq n}\phi(e_i,e_j)x_ix_j\]
    Une fonction de la forme \[f(x)=\sum_{i,j}a_{i,j}x_ix_j\] est dite polynomiale homogène de degré $2$.
\end{rem}


\begin{dfn}
Dans $k$ de caractéristique différente de $2$, on pose \[
\begin{array}{rrcl}
    \pi:& \Bil(E) & \longrightarrow & Q(E) \\
        & \phi & \longmapsto & \displaystyle (x \longmapsto \phi(x,x))
\end{array}
\] 
\end{dfn}

\begin{prop}
    $\pi$ est linéaire, surjective, et son noyau est exactement $\A(E)$.
\end{prop}

\begin{cor}
On sait $\Bil(E)=\S(E)\oplus \A(E)$, donc $\pi\left|_{\S(E)}\right.$ est un isomorphisme de $\S(E)$ dans $Q(E)$. Si $E$ est de dimension $n$, alors \[\dim Q(E)= \frac{n(n+1)}{2}\]
\end{cor}

\begin{dfn}
    Soit $q$ une forme quadratique. La forme polaire\index{forme polaire} de $q$ est l'unique $\phi \in  \S(E)$ telle que $\forall  x \in  E, q(x)=\phi(x,x)$.
\end{dfn}

\begin{prop}
    Soit $\phi \in  \Bil(E)$ et $q \in  Q(E)$ associée. Alors, la forme polaire de $q$ est \[\phi_s(x, y)=\frac12(\phi(x, y)+\phi(y, x))=\frac12(q(x+y)-q(x)-q(y))\]
    Cette dernière égalité est l'identité de polarisation\index{identité de polarisation}
\end{prop}

\begin{proof}
    $\phi_S$ est symétrique et $\pi(\phi_S)=q$, et \[q(x+y)-q(x)-q(y)= (\cdots )=\phi(x,y)+\phi(y,x)\]
\end{proof}

\begin{dfn}
    Soit $q \in  Q(E)$. Le rang de $q$ est le rang de sa forme polaire. On dit que $q$ est non-dégénérée si et seulement si sa forme polaire est non-dégénérée
\end{dfn}

\begin{prop}
Si $q \in  Q(E)$ et $F$ est un sev de $E$ alors $q\left|_F\right. \in  Q(F)$ et la forme polaire de cette restriction est la restriction de la forme polaire de $q$ à $F\times F$.
\end{prop}

\begin{rem}
Il est possible que $q$ soit non-dégénérée et que $q\left|_{F}\right.$ le soit.
\end{rem}

\section{Matrice d'une forme quadratique}

\begin{dfn}
    Soit $q \in  Q(E)$ et $\mathcal  B$ une base de $E$. La matrice de  $q$ dans la base  $\mathcal  B$ est $\mathcal  M_{\mathcal  B}(\phi)$ où $\phi$ est la forme polaire de  $q$.
\end{dfn}

\begin{ex}
    Prenons $E=k^n$ et  $q:E \longrightarrow k$ avec \[q(x)=\sum_{1\leq i\leq j\leq n}a_{i,j}x_ix_j\]
    Alors, la matrice $M$ de $q$ dans la base canonique est donnée par \[
    \begin{cases}
        M_{i,i}=a_{i,i}\text{ si }1\leq i\leq n\\
        M_{i,j}= \sfrac{a_{i,j}}2 \;\;\text{ si }\;\;i<j, \;\;\sfrac{a_{j,i}}2\;\;\text{ sinon }
    \end{cases}
    \] 
\end{ex}

\begin{prop}
    Soit $q \in  Q(E)$, $\mathcal  B, \mathcal  B'$ des bases de $E$ et $P \in  \GL_n(k)$ la matrice de passage de $\mathcal  B$ à $\mathcal  B'$. Alors $ \mathcal  M_{\mathcal  B'}(q)=\transpose P\mathcal M_{\mathcal  B}(q)P$
\end{prop}

\begin{proof}
Changement de base pour la matrice d'une forme bilinéaire
\end{proof}

\begin{dfn}
    Soit $q \in  Q(E)$ et $\mathcal  B$ une base de $E$. Le discriminant de  $q$ dans la base  $\mathcal  B$ est $\disc_{\mathcal  B}(q)=\det(\mathcal  M_{\mathcal  B}(q)) \in  k$.
\end{dfn}

\begin{rem}
    $q$ est dégénérée  si et seulement si $\disc_{\mathcal  B}(q)=0$
\end{rem}

\begin{dfn}
    On note $k /(k^\times)^2$ le quotient de $k$ par  $\sim$ définie par  \[
    x\sim y \iff  \exists  a \in  k^\times, \quad  x=a^2y
    \]
\end{dfn}

\begin{prop}
    L'image de $\disc_{\mathcal  B}(q)$ dans $k / (k^\times)^2 $ ne dépend pas de la base $ \mathcal B$
\end{prop}

\begin{proof}
 \[
     \det(\mathcal  M_{\mathcal  B'}(q))=\det(P)^2 \det (\mathcal  M_{\mathcal  B}(q))
\] 
\end{proof}

\begin{dfn}
    On note $\disc(q) \in  k / (k^\times)^2 $ l'image de $\disc_{\mathcal  B}(q)$ dans $k / (k^\times )^2 $.
\end{dfn}

\section{Isomorphisme de formes quadratiques}

\begin{dfn}
    Soient $E, E'$ des  ev et $q \in  Q(E), q' \in  Q(E')$. On dit que $q$ et  $q'$ sont isomorphes s'il existe un isomorphisme  $u:E\longrightarrow E'$ tel que $q=q'\circ u$
\end{dfn}

\begin{rem}
    Soient $\mathcal  B, \mathcal  B'$ des bases respectives de $E, E'$. Alors  $q$ et  $q'$ sont isomorphes  si et seulement si $\mathcal  M_{\mathcal  B} (q)$ et $\mathcal  M_{\mathcal  B'}(q')$ sont congruentes (i.e. $ \exists  P \in  \GL_n(k)$ tq $\mathcal M_{\mathcal  B'}(q')=\transpose P\mathcal  M_{\mathcal  B}(q)P$)
\end{rem}

\begin{prop}
    Si $q$ et  $q'$ sont isomorphes, alors elles ont même rang et même discriminant dans $k / (k^\times )^2 $.
\end{prop}

\begin{rem}
Ces invariants ne sont pas suffisant pour classifier les formes quadratiques à isomorphisme près
\end{rem}

\begin{ex}
$E=E'=\R^2 $, $k=\R$ et  \[
\begin{dcases}
    q(x, y)=x^2 +y^2 \\
    q'(x, y)=x^2 -y^2
\end{dcases}
\] 
Dans la base canonique, ces formes ont les matrices respectives $I_2$ et  $-I_2$, donc  $q$ et  $q'$ sont de rang  $2$. De plus,  $\disc(q)=1=\disc(q')$ dans  $ \R / (\R^\times )^2 $. Pourtant, $q$ et  $q'$ n'ont pas la même image (l'une est positive, l'autre non).
\end{ex}

\section{Orthogonalité et noyau}

On considère $q \in  Q(E)$, de forme polaire $\phi$.

 \begin{dfn}
Si $A\subseteq E$, on définit  \[
    A^{\bot,q}=A^{\bot,\phi}=L_\phi(A)^\bot=R_\phi(A)^\bot
\]
\end{dfn}

\begin{dfn}
    Le noyau de $q$ est  $\ker q=E^{\bot,q}= \left\{ x \in  E, \quad  \forall  y \in  E, \phi(x, y)=0 \right\} $. C'est un sev de $E$. On remarque que  $\phi$ est dégénérée  si et seulement si $\ker q\neq \left\{ 0 \right\} $
\end{dfn}

\begin{rem}
Si $F$ est un sev de $E$ alors $\ker (q)\cap F\subset \ker (q\left|_{F}\right.)$, mais il n'y a en général pas égalité en général.
\end{rem}

\begin{prop}
    Soit $V$ un sev de  $E$. Alors  $\dim V+\dim V^\bot \geq \dim E$, avec égalité si $q$ est non-dégénérée
\end{prop}

\begin{proof}
Vu pour les formes bilinéaires
\end{proof}

\begin{rem}
    Si $q$ est non-dégénérée, on n'a pas forcément  $V\oplus V^\bot=E$. Par exemple, pour  $q(x, y)=xy$ dans $k^2$,  $(ke_1)^\bot=ke_1$.
\end{rem}

\begin{prop}
On a $V\oplus V^\bot =E \iff  \disc(q\left|_{V}\right.)\neq 0$
\end{prop}

\begin{proof}
$\impliedby )$ Soit $x \in  V\cap V^\bot$. Alors, $\forall  y \in  V, \phi(x, y)=0$. Puisque $\phi\left|_{V^2}\right.$ est non-dégénérée, cela entraine $x=0$. Puis, la somme des dimensions est bonne.

$\implies )$ Soit $x \in  V$ tel que $\forall  y \in  V, \phi(x, y)=0$. Alors $x \in  V\cap V^\bot$ d'où $x=0$. Donc finalement  $\ker (q\left|_{V}\right.)= \left\{ 0 \right\} $
\end{proof}

\section{Cône isotrope d'une forme quadratique}

\begin{dfn}
    Le cône isotrope\index{cone isotrope@cône isotrope} de $q \in  Q(E)$ est l'ensemble \[
        C(q)= q^{-1}(\left\{ 0 \right\} )
    \]
\end{dfn}

\begin{rem}
\begin{itemize}
    \item $\ker q\subseteq C(q)$ mais il n'y a pas toujours égalité
    \item  $C(q)$ n'est pas un espace vectoriel
    \item  $C(q)$ est stable par multiplication par un scalaire (d'où le nom de cône).
\end{itemize}
\end{rem}

\begin{ex}
    Si $q(x, y)=xy$ alors  $C(q)=(ke_1)\cup (ke_2)$
\end{ex}

\section{Endomorphisme adjoint}

Soit $E$ un  $k$-e.v. de dimension finie et  $q \in  Q(E)$ non-dégénérée de forme polaire $\phi$

 \begin{defprop}
     Soit $u \in  \mathcal L(E)$. Il existe un unique $u^\star \in \mathcal  L(E)$ tel que \[
         \forall  x, y \in  E, \quad  \phi(u(x), y)=\phi(x, u^\star(y))
     \] 
     On appelle $u^\star$ l'adjoint de  $u$
\end{defprop}

\begin{proof}
L'unicité provient de la non-dégénrescence de $\phi$.

Posons  $u^\star = R_\phi ^{-1} \circ \transpose u\circ R_\phi$. Soient $x, y \in  E$. On a \[
    \phi(x, u^\star(y))=R_\phi(u^\star(y))(x)=\transpose u(R_\phi(y))(x)=(R_\phi(y)\circ u)(x)=\phi(u(x), y)
\] 
\end{proof}

\begin{prop}
    Soit $u \in \mathcal  L(E)$. Alors \[
    \begin{dcases}
        \ker(u)^\bot=\im(u^\star)\\
        \im(u)^\bot=\ker(u^\star)
    \end{dcases}
    \] 
\end{prop}

\begin{proof}
Voir le chapitre sur les formes linéaires
\end{proof}

\begin{prop}
L'application $u\longmapsto u^\star$ est linéaire, bijective et involutive.
\end{prop}

\section{Réduction des formes quadratiques}

\begin{dfn}
    Soit $q \in  Q(E)$ et $(e_1, \cdots , e_n)$ une famille de vecteurs de $E$. Cette famille est dite orthogonale pour  $q$  si et seulement si \[
        \forall  i,j \in  \llbracket 1, n \rrbracket , \qquad  i\neq j \implies \phi(e_i, e_j)=0
    \] 
\end{dfn}

\begin{thm}
    Soit $q \in  Q(E)$. Il existe une base orthogonale de $E$ pour  $q$.
\end{thm}

\begin{proof}
On procède par récurrence $n=\dim E$
\begin{itemize}
    \item Si $n=1$, il n'y a rien à faire
\item Supposons $n\geq 2$. Si $q=0$ alors toutes les bases conviennent. Sinon, il existe  $x \in  E$ tel que $q(x)=0$. Posons $H=(kx)^\bot$. Puisque  $q\left|_{kx}\right.$ est non dégénérée, on a (déjà vu) $kx\oplus H=E$. Il suffit d'appliquer l'hypothèse de récurrence pour conclure. 
\end{itemize}
\end{proof}

\begin{thm}
    Soit $q \in  Q(E)$, il existe $(\lambda_1, \cdots , \lambda_m)$ une famille de formes linéaires indépendantes sur $E$ et  $(a_1, \cdots , a_m)$ une famille de scalaires tels que \[
        \forall  x \in  E, q(x)=\sum_{i=1}^m a_i (\lambda_i(x))^2 
    \] 
    On a alors $\rg(q)=m$ et  \[
        \disc(q)=\prod_{i=1}^m a_i \in  k / (k^\times )^2 
    \]
    La forme quadratique $q$ est non-dégénérée  si et seulement si $n=m$.
\end{thm}

\begin{proof}
    Soit $(e_1, \cdots , e_n)$ une base orthogonale de $E$ pour  $q$. Soit  $(\lambda_1, \cdots , \lambda_n)$ la base duale de $(e_1, \cdots , e_n)$. Puis, on note $a_i=q(e_i)$. Si  \[
    x= \sum_{i=1}^n x_ie_i
    \] 
    alors \[
        q(x)= \sum_{1\leq i,j\leq n} \phi(e_i, e_j)x_ix_j=\sum_{i=1}^m a_i (\lambda_i(x))^2 
    \] 
    Considérons \[
        M=\mathcal  M_{(e_1, \cdots , e_n)}(q)=
        \begin{pmatrix}
            a_1 & \cdots  & 0 \\
            \vdots & \ddots & \vdots \\
            0 & \cdots  & a_n
        \end{pmatrix}
    \] 
    Les considérations sur le rang, le discriminant et la non-dégenerescence sont claires.
\end{proof}

\begin{rem}
L'écriture n'est pas unique
\end{rem}

\section{Algorithme de Gauss}

On se donne un polynôme $P(X_1, \cdots , X_n) \in  k[X_1, \cdots , X_n]$ homogène de degré 2. On veut écrire $P$ comme combinaison linéaire de carrés de polynômes homogènes de degré  $1$ de sorte que les formes linéaires associées soient linéairement indépendantes.

On raisonne par récurrence sur le nombre de variables. Si $n=1$ alors il n'y a rien à faire. Pour $n$ quelconque, il y a deux cas
 \begin{itemize}
    \item Premier cas: il existe $i$ tel que  $a_{i,i}\neq 0$. Sans perdre de généralité, on suppose $i=1$. Dans ce cas,  \[
            P(X_1, \cdots , X_n)=a_{1,1} X_1 ^2 + X_1 L(X_2, \cdots , X_n) + Q(X_2, \cdots , X_n)
    \] 
    avec $L$ une forme linéaire et  $Q$ homogène de degré  $2$. On écrit  \[
        P = a_{1, 1} \left( X_1 + \frac{L}{2a_{1,1}} \right)^2 +Q - \frac{L^2 }{4a_{1,1}}
    \]
    Et par hypothèse de récurrence, on peut continuer pour $Q$.
\item Second cas: $\forall  i \in \llbracket 1, n \rrbracket , a_{i, i}=0$. Alors il existe (on suppose que $q\neq 0$) $i,j$ tels que  $i\neq j$ et  $a_{i,j}\neq 0$. Sans perdre de généralité, on suppose $i=1, j=2$. On écrit \[
        P=a_{1,2}X_1X_2+X_1 L_1(X_2, \cdots , X_n)+X_2 L_2(X_3, \cdots , X_n)+Q(X_3, \cdots , X_n)
\] 
de sorte que \[
    P= \frac{a_{1,2}}{4} \left( \left( X_1+X_2+\frac{L_1+L_2}{a_{1,2}} \right)^2 - \left( X_1-X_2 + \frac{L_2-L_1}{a_{1,2}} \right) ^2 \right)  - \frac{L_1L_2}{a_{1, 2}}+Q
\] 
et par récurrence, on conclut. L'indépendance des formes linéaires qui apparaissent est claire (combinaisons linéaires d'une base triangulaire)
\end{itemize}

\begin{rem}
Si \[
q=\sum_{i=1}^n a_i \lambda_i^2 
\] 
alors la base antéduale des $(\lambda_i)$ est une base orthogonale de $E$ pour  $q$.
\end{rem}

\section{Formes quadratiques sur \texorpdfstring{$ \C$}{C}}

\begin{thm}
    On suppose $k=\C$ (ou plus généralement, $k$ tel que tout élément est un carré). Dans ce cas, si  $q \in  Q(E)$ alors il existe une base $\mathcal  B$ orthogonale pour  $q$ telle que  \[
        \mathcal  M_{\mathcal  B}(q)=\Jr{m}
    \] 
    pour un certain $m\leq n$
\end{thm}

\begin{proof}
    Soit $(e_1, \cdots , e_n)$ une base orthogonale de $E$ pour  $q$. Alors il existe des scalaires  $ \lambda_i$ tels que \[
        \mathcal  M_{(e_1, \cdots , e_n)}(q)=
        \begin{pmatrix}
            \lambda_1 & \cdots  & 0 \\
            \vdots & \ddots & \vdots \\
            0 & \cdots  & \lambda_n
        \end{pmatrix}
    \] 
    Quitte à permuter les vecteurs de la base, on peut supposer que les $m$ premiers sont non nuls et les  $n-m$ suivants le sont. On écrit  $ \lambda_i=\alpha_i^2 $ avec $\alpha_i \in  k^\times$ pour $i\leq m$ et on pose \[
        \mathcal  B= \left( \frac{e_1}{\alpha_1}, \cdots , \frac{e_m}{\alpha_m}, e_{m+1}, \cdots , e_n\right)
    \] 
    et cela convient.
\end{proof}

\begin{cor}
Soit $E$ un  $\C$-espace vectoriel. Alors, deux formes quadratiques sur $E$ sont isomorphes  si et seulement si elles ont le même rang.
\end{cor}

\section{Formes quadratiques sur \texorpdfstring{$\R$}{R}}

\begin{prop}
    Soit $E$ un  $ \R$-ev, et $q \in  Q(E)$. Alors il existe une base $\mathcal  B$ de $E$ orthogonale pour  $q$ telle que 
     \[
         \mathcal  M_{\mathcal  B}(q)=\diag(\underbrace{1, \cdots , 1}_r, \underbrace{-1, \cdots , -1}_s, 0, \cdots , 0)
    \] 
\end{prop}

\begin{proof}
C'est la même chose que dans le cas complexe, avec un signe pour les négatifs.
\end{proof}

\begin{dfn}
    Soit $q \in  Q(E)$. On dit que $q$ est positive si \[
        \forall  x \in  E, q(x)\geq 0
    \] 
    On dit qu'elle est définie positive si cette inégalité est stricte dès que $x\neq 0$.

    On dit que $q$ est définie si elle est définie positive ou définie négative
\end{dfn}

\begin{rem}
    Avec les notations de la proposition ci-dessus, on a $q$ positive  si et seulement si $s=0$ et  $q$ définie positive  si et seulement si $(r, s)=(n, 0)$
\end{rem}

\begin{thm}
Supposons que \[
    q=\sum_{i=1}^r a_i \lambda_i^2 -\sum_{i=r+1}^{r+s}a_i \lambda_i^2 
\] 
avec $ \lambda_1, \cdots , \lambda_{r+s}$ linéairement indépendantes. Alors \[
    \begin{dcases}
r=\max \left\{ \dim F, \quad  F \text{ sev  de }  E \text{ et } q\left|_{F}\right. \text{ définie positive }\right\} \\
s=\max \left\{ \dim F, \quad  F \text{ sev  de }  E \text{ et } q\left|_{F}\right. \text{ définie négative }\right\} 
    \end{dcases}
\] 
\end{thm}

\begin{proof}
    On complète $(\lambda_i)$ en une base $(\lambda_1, \cdots , \lambda_n)$ de $E$. Soit  $\mathcal  B=(e_1, \cdots , e_n)$ la base antéduale dans $E$.
    
    On sait que $q_{|\Vect(e_1, \cdots , e_r)}$ est définie positive donc $r$ est inférieur au maximum de l'énoncé.

Soit $F$ un sev de $E$ de dimension $r+1$ tel que $q \left|_{F}\right.$ est définie positive. On définit $F_+=\Vect(e_1, \cdots , e_r)$, $F_-=\Vect(e_{r+1}, \cdots , e_{r+s})$ et $F_0=\Vect(e_{r+s+1}, \cdots , e_n)$. On a $\dim(F_-\oplus F_0)=n-r$ donc $F\cap (F_-\oplus F_0)\neq \left\{ 0 \right\} $. Soit $x \in  F\cap (F_-\oplus F_0)$ non nul. Alors, $q(x)>0$. Mais, $q\left|_{F_-\oplus F_0}\right.$ est négative donc $q(x)\leq 0$, ce qui est absurde.

La démonstration pour $s$ est similaire.
\end{proof}

\begin{thm}[Théorème d'inertie de Sylverster\index{Sylvester (théorème d'inertie)}\index{inertie (théorème de Sylvester)}]
    Le couple $(r, s)$ ne dépend que de  $q$ et pas de sa décomposition. De plus,  $\rg(q)=r+s$ et  $\disc(q)=0$ si  $r+s<n$,  $(-1)^s$ sinon. On appelle signature\index{signature} de $q$ le couple  $(r, s)$
\end{thm}

\begin{rem}[Résumé]
    Deux formes quadratiques sur $ \R$ sont isomorphes si et seulement si elles ont la même signature (qui peut être calculée par l'algorithme de Gauss)
\end{rem}

\begin{rem}[Cône isotrope]
    Soit $q \in Q(\C^n)$ non dégénérée. Alors, $C(q)= \left\{ 0 \right\} \iff  n=1$. En effet, dans une certaine base, $q(x)= \sum_i x_i^2 $ et dans la bonne base, $(1, i, 0, \cdots , 0) \in  C(q)$ pour $n\geq 2$

    Si on se donne cette fois $q \in  Q(\R^n)$ non dégénérée de signature $(r, s)$, on a $C(q)= \left\{ 0 \right\}  \iff  r=0 \text{ ou }s=0$
\end{rem}

\section{Quelques résultats sur \texorpdfstring{$ \R$}{R}}

Soit $E$ un  $ \R$-espace vectoriel de dimension finie. Se donner un produit scalaire sur $E$ revient à se donner une forme quadratique définie positive sur  $E$. On note $\scalar{\;}{\;} $ la forme polaire de $q$, et  \[
    \|x\|=\sqrt{\scalar{x}{x} }=\sqrt{q(x)}
\] 

\begin{dfn}
    Soit $u \in  \mathcal  L(E)$. On dit que $u$ est orthogonal pour  $q$  si et seulement si $uu^\star=\id_E$. On note  $\O(q)$ l'ensemble des endomorphismes orthogonaux de  $E$ (le groupe orthogonal\index{groupe orthogonal})
\end{dfn}

\begin{rem}
\[
    u \in  O(q) \iff  \forall  x, y \in E, \qquad  \scalar{u(x)}{u(y)} =\scalar{x}{y} 
\] 
\end{rem}

\begin{rem}
    On peut définir le groupe orthogonal pour tout corps $k$, tout  $k$-espace vectoriel  $E$ et toute forme quadratique  $q \in  Q(E)$ non dégénérée.

    Si $k=\R$ et $q$ est de signature  $(r, s)$, on note  $O(r, s)=O(q)$ pour  $E=\R^n$.
\end{rem}

\begin{dfn}
    On dit que $u \in  \mathcal  L(E)$ est symétrique si et seulement si \[
        \forall  x, y \in  E, \qquad  \scalar{u(x)}{y} = \scalar{x}{u(y)} 
    \] 
    Cela revient à dire $u=u^\star$
    On note  $S(E)$ le sous-espace vectoriel formé  des endomorphismes symétriques.
\end{dfn}

\begin{prop}
    Soit $\mathcal  B$ une base orthonormée de $(E, \scalar{\;}{\;} )$. Alors, $u \in  \mathcal  L(E)$ est symétrique si et seulement si $\mathcal M_{\mathcal  B}(u)$ est symétrique
\end{prop}

\begin{dfn}
    Soit $u \in  \S(E)$. On dit que $u$ est positive si  $q_u: x \in  E \longrightarrow \scalar{u(x)}{x} $ l'est. On notera $\S^+(E)$ l'ensemble de ces endomorphismes. Puis, si  $q_u$ est définie, on dit que  $u$ aussi et on note  $\S^{++}(E)$ l'ensemble des endomorphismes définis positifs.
\end{dfn}

\begin{thm}
    Si $u \in \S(E)$, alors $u$ est diagonalisable.% dans une base orthonormée.
\end{thm}

\begin{proof}
    % Considérons la décomposition de $\chi_u$ en irréductibles de  $\R[X]$. Soit $P$ un facteur irréductible de degré  $2$, de racines  $ \lambda, \bar\lambda$. On note $M=\mathcal  M_{\text{canon}}(u)$. Il existe $Q \in  \GL_n(\C)$ tel que \[
    % QMQ^{-1}=
    % \left(
    % \begin{array}{cc|c}
    %     \lambda & 0 & \star \\
    %      0 & \bar\lambda & \star \\
    %     \hline 0 & 0 &  \\
    %     \vdots & \vdots & \star \\
    %     0 & 0 & 
    % \end{array}
    % \right)
    % \] 
    % et alors $P(QMQ^{-1})=QP(M)Q^{-1}$ a ses deux premières colonnes nulles donc $P(u)$ n'est pas inversible dans  $E$. Soit  $x \in  E\setminus \left\{ 0 \right\}   $ tel que $P(u)(x)=0$. Soit  $F=\Vect(x, u(x))$, qui est stable par  $u$. Soit  $\mathcal  B$ une base orthonormale de $F$. Le discriminant du polynôme caractéristique de   $\mathcal  M_{\mathcal  B}(u)$ est positif, ce qui est absurde.
    On note $\mathcal  B$ une base orthonormée de $E$,  $A=\mathcal  M_{\mathcal  B}(u) \in \S_n(\R)$. Soit $ \lambda \in  \Sp_{\C}(A)$ et $X \in \C^n$ un vecteur propre associé. On a 
\begin{align*}
    \transpose \bar X AX &= \lambda \transpose \bar XX \\
                         &= \transpose \bar X\transpose \bar AX\\
                         &= \transpose (\bar{A X})X \\
                         &= \bar\lambda \transpose \bar XX
\end{align*}
    donc $ \lambda=\bar\lambda$ et $\lambda \in  \R$. On a donc $\Sp_{\C}(A)\subset \R$. Puis, $\chi_A$ est scindé en tant que polynôme complexe, et a ses racines dans $\R$ et est donc scindé dans $\R[X]$.
\end{proof}

\begin{thm}
    Soit $u \in  \S(E)$. Alors il existe une base orthonormée de $E$ qui diagonalise  $u$. Réciproquement, si  $u \in  L(E)$ peut être diagonalisée dans une base orthonormée, alors  $u$ est symétrique.
\end{thm}

\begin{lmm}
    Soit $u \in  \S(E)$. Alors ses valeurs propres sont réelles.
\end{lmm}

\begin{lmm}
    Soit $u \in  \S(E)$ et $F\subset E$ stable par  $u$. Alors,  $F^\bot$ est aussi stable par  $u$
\end{lmm}

\begin{proof}[Preuve du second lemme]
    Si $x \in  F^\bot, y \in  F$ alors $ \scalar{u(x)}{y}= \scalar{x}{u(y)}=0  $ donc $u(x)\in F^\bot$
\end{proof}

\begin{proof}[Preuve du théorème]
    Soit $u \in  \S(E)$. On fait une récurrence sur $n=\dim E$. Si  $n=1$, il n'y a rien à faire. Sinon, soit  $x\in  E$ un vecteur propre unitaire de $u$. On pose $F=\R x$ et $E=F\oplus F^\bot$ et  $F^\bot$ est stable par  $u$ donc  $u\left|_{F^\bot}\right.$ se diagonalise dans une base orthonormée, ce qui conclut.
\end{proof}

% TODO: les corollaires de sasha

\begin{cor}
    $u \in  \S(E)$. Alors $q_u(x)= \scalar{u(x)}{x} $ est une forme quadratique. Il existe une base orthonormée de $E$ orthogonale pour $q_u$.
\end{cor}

\begin{cor}
    Soient $A, B \in  \S_n(\R)$, avec $A \in  \S_n^{++}(\R)$. Alors il existe $P \in  \GL_n(\R)$ tel que \[
        \transpose PAP=I_n \qquad \text{et}\qquad  \transpose PBP\text{ diagonale }
    \]
\end{cor}

% TODO: rattraper ça aussi

\section{Décomposition polaire}

\begin{prop}
    Soit $u \in  \S^{++}(E)$. Alors il existe un unique $v \in  \S ^{++}(E)$ tel que $v^2 =u$. Puis, $v$ est polynomial en  $u$.
\end{prop}

\begin{proof}
    Soit $(e_1, \cdots , e_n)$ une BON qui diagonalise $u$:  $ u(e_i)=\lambda_i e_i$. On pose $v(e_i)=\sqrt{\lambda_i}e_i$, on a bien  $v \in  \S ^{++}(E)$.

    Si $P \in  \R[X]$ est tel que $P(\lambda_i)=\sqrt{\lambda_i}$ alors  $P(u)=v$. Pour l'unicité, on se donne  $w$ qui convient. Les applications  $w$ et  $u$ commutent donc il existe une base de diagonalisation commune, et dans cette base on peut identifier les valeurs propres. Puis  $E=\bigoplus E_{\lambda_i}^u$ et  ces espaces propres sont stables par  $w$, puis  $E_{\lambda_i}^u=E_{\sqrt{\lambda_i}}^w$ donc  $v=w$.
\end{proof}

\begin{thm}[Décomposition polaire]
    On se donne $g \in  \GL{E}$. Il existe un unique $u \in  \O(E)$ et $s \in  \S ^{++}(E)$ tels que $g=us$. De plus,  $s$ est un polynôme en  $g^\star=g$
\end{thm}

\begin{proof}
    Remarquons que $h\defeq g^\star g \in  \S ^{++}(E)$, puisque $h^\star=(g^\star g)^\star=g^\star g=h$. Puis, si  $\lambda$ est une valeur propre de  $h$ et  $x$ un vecteur propre associé, alors  \[
        \scalar{h(x)}{x} = \scalar{\lambda x}{x} = \lambda \|x\|^2 = \scalar{g^\star g (x)}{x} = \|g(x)\|^2 
    \] 
    donc $ \lambda >0$. Il existe $s \in \S^{ ++ }(E)$ tel que $s^2 =h$. On pose $u=gs^{-1}$ de sorte que $g=us$. Puis  \[
    u^\star u=s^{-1}g^\star g s^{-1}=s ^{-1} s^2 s ^{-1}=\id
    \] 
    d'où $u \in  \O(E)$, ce qui conclut sur l'existence.

    Pour l'unicité, on peut remarquer que $g^\star g=s^2$ donc  $s$ est uniquement déterminé par  $g$.
\end{proof}
